
Outline of Mandarin-English Code-Switching Final Project

Title: 

Introduction
Why is the phenomenon of English-Mandarin code-switching interesting/important?
Attests to the ability of speakers to communicate in diverse languages rather than suggesting lack of competence through a need to supplement one language with another (Code-Switching in Chinese Malaysian Communities in the Film The Journey (2014) Modh et al)
Reveals the language in which native speakers have internalized concepts (Blogs by Young Macao People  )
May indicate which of the non-native words are more rapidly accessed or retrieved by bilingual people and consequently get embedded/inserted more frequently into mixed-language speech (A comparison of adjective and noun retrieval)
Two relevant groups of Mandarin-English bilingual people
			Native English speakers 
			Native Mandarin speakers
Countless factors contribute to retrieval time:
Syllable structure and syllable count
Do Mandarin speakers insert monosyllabic words more frequently into their mixed Mandarin-English?
Out of the multisyllabic English words scattered in English speech, what proportion of them conform with the Mandarin syllable template inventory?
Part of Speech (a.k.a., lexical category)
Research Question:Are some lexical categories of non-native, switched words more frequently recollected than others in spontaneous fluent mixed-language speech?
This project will concentrate on analyzing the part of speech distribution of the switched, non-native words.
Hypothesis: Non-native verbs are more frequently recalled in spontaneous, fluent mixed-language speech than non-native nouns because the retrieval time was shorter for non-native verbs than non-native nouns in the Picture Naming Experiment.

Background

Picture Naming Experiment
In the article titled â€œA Comparison of Noun and Verb Retrievalâ€, 21 Mandarin-English bilinguals native in only Mandarin and 21 English monolinguals recalled nouns in response to sketches of objects and recalled verbs in response to sketches of actions. 
Each noun or verb picture naming task was rated 0 for inaccurate and 1 for accurate, plus the retrieval time for each task was also logged.
Mandarin-English bilinguals scored higher for verbs in terms of retrieval rate but higher for nouns in terms of accuracy.
Retrieval rate is a greater indicator of whether a word gets uttered in spontaneous, fluent conversation, so again, we expect the non-native verb count to surpass the non-native noun count in a code-switching corpus.

Methods
SEAME is a Mandarin-English code-switching corpus replete with 192 hours of interview question-facilitated casual conversations. SEAME-dev-set contains two repackaged SEAME-derived test sets of mixed-language speech, one Mandarin-dominated and one Singaporean English-dominated. Keep in mind that SEAME only reflects only code-switching in Mandarin diasporan communities of Singapore and Malaysia. Any unexpected discrepancies between part of speech distribution in SEAME-dev-set and the noun and word retrieval experiment could result from different populations surveyed or different circumstances. The word retrieval in SEAME transpired in conversation unlike how word retrieval in the noun and word retrieval experiment occurred in response to pictures.

The data collection and curation process is as follows:
One Mandarin-dominated test set (dataset1.txt), wherein presumably English is the non-native language, and one English-dominated test set (dataset2.txt), wherein presumably Mandarin is the non-native language, were imported from zengzp0912's repository. 
We will convert both dataset1.txt and dataset2.txt to a csv with a NumberTag column and a MandEngSpeech column.
We will read each MandEngSpeech column into a list, titling the list mandEngSpeech for dataset1.txt and MandengSpeech for dataset2.txt.
We will filter out the English fillers (e.g., "um", "eh"); interjections or abrupt sentence-initial words like "ah," "ha", and "hey"; and proper nouns (e.g., Backstreet Boys) from each string in each list by iterating through lists of fillers, interjections, and proper nouns.
If Max is knowlegdeable of fillers, interjections, and proper nouns in Mandarin, then we will filter out those from the both lists of mixed Mandarin-English sentences.


We will initialize lists mandEngSpeech_tokens and MandengSpeech_tokens.

We will import nltk, download popular, and import spacy in order to word tokenize each string, decomposing it into words tokens and punctuation mark tokens.
We will append each tokenized string of mandEngSpeech to mandEngSpeech_tokens and each tokenized string of MandengSpeech to MandengSpeech_tokens.

initialize noun counter
initialize verb counter
for item in mandEngSpeech_tokens
	count the number of nouns in item 
		-> add to noun counter
	count the number of verbs in item
		->add to verb counter
		
print(noun counter)
print(verb counter)

initialize new noun counter
initialize new verb counter
for item in mandEngSpeech_tokens
	count the number of nouns in item 
		-> add to new noun counter
	count the number of verbs in item
		->add to new verb counter
		
print(new noun counter)
print(new verb counter)
